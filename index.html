<script src="http://www.google.com/jsapi" type="text/javascript"></script> 
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
	body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif; 
		font-weight:300;
		font-size:18px;
		margin-left: auto;
		margin-right: auto;
		width: 1100px;
	}
	
	h1 {
		font-size:32px;
		font-weight:300;
	}
	
	.disclaimerbox {
		background-color: #eee;		
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.rounded {
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	a:hover {
		color: #208799;
	}
	
	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}
	
	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		15px 15px 0 0px #fff, /* The fourth layer */
		15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		20px 20px 0 0px #fff, /* The fifth layer */
		20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		25px 25px 0 0px #fff, /* The fifth layer */
		25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}

	.paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35); /* The top layer shadow */

		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}

	.vert-cent {
		position: relative;
		top: 50%;
		transform: translateY(-50%);
	}

	hr
	{
		border: 0;
		height: 1px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}

	/* For domain name */
	.texttt{
		font-family: "Courier New";
		font-weight: bold;
	}

	/* For dataset items */
	.list_no_bullet{
		list-style-type: none; /* Remove bullets */
		padding-left: 40px; /* Remove padding */
		margin: 0; /* Remove margins */
	}

	.item{
		font-family: "Courier New";
		color: rgb(236, 18, 145);
	}

</style>

<!-------------------------------------------------------------------------------->
<!------------------------------  Main Contents  --------------------------------->
<!-------------------------------------------------------------------------------->

<html>
<head>
	<title>SHIRT: Satellite Hardware-In-the-loop Rendezvous Trajectory Dataset</title>
	<meta property="og:image" content="Path to my teaser.png"/> <!-- Facebook automatically scrapes this. Go to https://developers.facebook.com/tools/debug/ if you update and want to force Facebook to rescrape. -->
	<meta property="og:title" content="SHIRT: Satellite Hardware-In-the-loop Rendezvous Trajectories Dataset" />
	<meta property="og:description" content="Paper description." />

	<link rel="stylesheet" href="resources/fontawesome/css/fontawesome.css">
	<link rel="stylesheet" href="resources/fontawesome/css/solid.css">

	<!-- Get from Google Analytics -->
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<!-- <script async src=""></script> 
	<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());

		gtag('config', 'UA-75863369-6');
	</script> -->
</head>

<body>
	<br>

	<!----- Title, Authors ------->

	<center>
		<span style="font-size:36px">SHIRT: Satellite Hardware-In-the-loop Rendezvous Trajectories Dataset</span>
		<table align=center width=600px>
			<table align=center width=600px>
				<tr>
					<td align=center width=100px>
						<center>
							<span style="font-size:24px"><a href="https://taehajeffpark.com">Tae Ha Park</a></span>
						</center>
					</td>
					<td align=center width=100px>
						<center>
							<span style="font-size:24px"><a href="https://slab.stanford.edu">Simone D'Amico</a></span>
						</center>
					</td>
				</tr>
			</table>
			<br>

			<table align=center width=500px>
				<tr>
					<td align=center width=250px>
						<center>
							<span style="font-size:24px"><a href="https://purl.stanford.edu/zq716br5462">[Stanford Digital Repository]</a></span>
						</center>
					</td>
					<td align=center width=150px>
						<center>
							<span style="font-size:24px"><a href="./resources/bibtex_sdr.txt">[BibTeX]</a></span>
						</center>
					</td>
				</tr>
			</table>
			<br>

		</table>
	</center>

	<!----- Teaser items ------->

	<center>
		<table align=center width=850px>
			<tr>
				<td width=260px>
					<center>
						<img class="round" style="width:768px" src="./resources/teaser.gif">
					</center>
				</td>
			</tr>
		</table>
		<table align=center width=850px>
			<tr>
				<td>
					<center>
						<!-- This was a template originally made for <a href="http://richzhang.github.io/colorization/">Colorful Image Colorization</a>. The code can be found in this <a href="https://github.com/richzhang/webpage-template">repository</a>. -->
						Example low-resolution images of the <span class="texttt">synthetic</span> and <span class="texttt">lightbox</span> domains of ROE2 trajectory.
					</center>
				</td>
			</tr>
		</table>
	</center>

	<br>
	<hr>

	<!----- Introduction ------->

	<table align=center width=850px>
		<center><h1>Introduction</h1></center>
		<tr>
			<td>
				Deploying deep learning models into space missions is difficult due to the scarcity of real-life data from space.
                Particularly in spaceborne computer vision applications, while training can rely on synthetic data from computer renderers, 
                the validation of the trained neural networks remains a big challenge. Our <a href="https://ieeexplore.ieee.org/document/9843439">SPEED+</a> dataset
                addressed this challenge by introducing Hardware-In-the-Loop (HIL) images captured from the 
                <a href="https://taehajeffpark.com/files/papers/parkbossedamico_aas2021.pdf">Testbed for Rendezvous and Optical Navigation (TRON)</a> facility 
                at the <a href="https://slab.stanford.edu">Space Rendezvous Laboratory (SLAB)</a>. Amounting to nearly 10,000 in quantity, these HIL images
                are captured with a real camera and a mockup satellite model in high-fidelity spaceborne illumination conditions physically re-created on Earth,
                making it possible to evaluate the robustness of trained models across domain gap without accessing space.
                <br><br>
                The Satellite Hardware-In-the-loop Rendezvous Trajectories (SHIRT) dataset extends SPEED+ and includes <b>sequential</b> images
                of the target mockup satellite in simulated rendezvous trajectories. Similar to SPEED+, the dataset contains both <span class="texttt">synthetic</span> imagery from 
                OpenGL and HIL <span class="texttt">lightbox</span> images from TRON corresponding to identical pose labels of two representative rendezvous scenarios: ROE1 and ROE2.
				In ROE1, the servicer maintains the along-track separation typical of a standard v-bar hold point while the target spins about one principal axis, 
				whereas in ROE2, the servicer slowly approaches the target tumbling about two principal axes. 
				As shown in the GIF above, the <span class="texttt">synthetic</span> and <span class="texttt">lightbox</span> images for the same trajectory
				share geometric and illumination consistency while also exhibiting stark difference in visual features. For more information, see 
				Section V of the paper below.
			</td>
		</tr>
	</table>

	<br>
	<hr>

	<!----- Dataset Format ------->

	<table align=center width=850px>
		<center><h1>Format</h1></center>
		<tr>
			<td>
				The SHIRT data is hosted on the <a href="">Stanford Digital Repository (SDR)</a> and is released under 
				the <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> license. The single .zip file (3.01GB)
				containing the dataset is organized as shown below:
				<br><br>
				<ul class="list_no_bullet">
					<li><i class="fa-solid fa-folder-open"></i> <span class="item">roe1</span></li>
					<ul class="list_no_bullet">
						<li>- <i class="fa-solid fa-folder-open"></i> <span class="item">synthetic</span></li>
						<ul class="list_no_bullet">
							<li>- <i class="fa-solid fa-folder-open"></i> <span class="item">images</span>: folder containing JPEG images of the ROE1 <span class="texttt">synthetic</span> trajectory </li>
						</ul>
						<li>- <i class="fa-solid fa-folder-open"></i> <span class="item">lightbox</span></li>
						<ul class="list_no_bullet">
							<li>- <i class="fa-solid fa-folder-open"></i> <span class="item">images</span>: folder containing JPEG images of the ROE1 <span class="texttt">lightbox</span> trajectory</li>
						</ul>
						<li>- <i class="fa-solid fa-file-lines"></i> <span class="item">roe1.json</span>: list of all file names and associated pose labels</li>
						<li>- <i class="fa-solid fa-file-lines"></i> <span class="item">metadata.json</span>: list of all metadata, such as absolute states and simulation parameters</li>
					</ul>
					<li><i class="fa-solid fa-folder-open"></i> <span class="item">roe2</span></li>
					<ul class="list_no_bullet">
						<li>- <i class="fa-solid fa-folder-open"></i> <span class="item">synthetic</span></li>
						<ul class="list_no_bullet">
							<li>- <i class="fa-solid fa-folder-open"></i> <span class="item">images</span>: folder containing JPEG images of the ROE2 <span class="texttt">synthetic</span> trajectory</li>
						</ul>
						<li>- <i class="fa-solid fa-folder-open"></i> <span class="item">lightbox</span></li>
						<ul class="list_no_bullet">
							<li>- <i class="fa-solid fa-folder-open"></i> <span class="item">images</span>: folder containing JPEG images of the ROE2 <span class="texttt">lightbox</span> trajectory</li>
						</ul>
						<li>- <i class="fa-solid fa-file-lines"></i> <span class="item">roe2.json</span>: list of all file names and associated pose labels</li>
						<li>- <i class="fa-solid fa-file-lines"></i> <span class="item">metadata.json</span>: list of all metadata, such as absolute states and simulation parameters</li>
					</ul>
					<li><i class="fa-solid fa-file-lines"></i> <span class="item">camera.json</span>: list of camera intrinsic parameters</li>
					<li><i class="fa-solid fa-file-lines"></i> <span class="item">LICENSE.md</span>: dataset license file</li>
					<li><i class="fa-solid fa-file-lines"></i> <span class="item">METADATA.md</span>: file explaining the content of <span class="item">metadata.json</span> files</li>
				</ul>
			</td>
		</tr>
	</table>

	<br>
	<hr>

	<!----- Paper ------->
	<table align=center width=800px>
		<center><h1>Paper and Supplementary Material</h1></center>
		<tr>
			<td><a href="https://arxiv.org/abs/2206.03796"><img class="layered-paper-big" style="height:175px" src="./resources/paper.png"/></a></td>
			<td><span style="font-size:14pt">Park, T. H., D'Amico, S.<br>
				<b>Adaptive Neural-Network-Based Unscented Kalman Filter for Robust Pose Tracking of Noncooperative Spacecraft.</b><br>
				Journal of Guidance, Control, and Dynamics (2023).<br>
				<!-- (<a href="./resources/camera-ready.pdf">camera ready</a>)<br> -->
				<span style="font-size:4pt"><a href=""><br></a>
				</span>
			</td>
		</tr>
	</table>
	<br>

	<table align=center width=200>
		<tr>
			<td><span style="font-size:14pt"><center>
				<a href="https://arxiv.org/abs/2206.03796">[arXiv]</a>
			</center></td>
			<td><span style="font-size:14pt"><center>
				<a href="https://arc.aiaa.org/doi/full/10.2514/1.G007387">[Official]</a>
			</center></td>
			<td><span style="font-size:14pt"><center>
				<a href="./resources/bibtex_paper.txt">[Bibtex]</a>
			</center></td>
		</tr>
	</table>

	<br>
	<hr>


	<!----- Acknowledgement ------->

	<table align=center width=900px>
		<tr>
			<td width=400px>
				<left>
					<center><h1>Acknowledgements</h1></center>
					The authors would like to thank OHB Sweden for the 3D model of the Tango spacecraft used to create the images. 
					This work is partially supported by Taqnia International through contract 1232617-1-GWNDV.
					<br><br>
					This template was originally made by <a href="http://web.mit.edu/phillipi/">Phillip Isola</a> and 
					<a href="http://richzhang.github.io/">Richard Zhang</a> for a <a href="http://richzhang.github.io/colorization/">colorful</a> 
					ECCV project; the code can be found <a href="https://github.com/richzhang/webpage-template">here</a>.
				</left>
			</td>
		</tr>
	</table>

<br>
</body>
</html>

